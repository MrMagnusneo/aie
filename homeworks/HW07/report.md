# HW07 – Report
Файл: `homeworks/HW07/report.md`

## 1. Datasets
Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 A
Файл: `data/S07-hw-dataset-01.csv`  
Размер: (7602, 9)  
Признаки: все числовые  
Пропуски: нет  
"Подлости" датасета: разные шкалы признаков, наличие выбросов, нелинейные зависимости между признаками

### 1.2 B
Файл: `data/S07-hw-dataset-02.csv`  
Размер: (7625, 4)  
Признаки: все числовые  
Пропуски: нет  
"Подлости" датасета: наличие шумовых точек, кластеры различной плотности, сложная геометрия кластеров

### 1.3 C
Файл: `data/S07-hw-dataset-03.csv`  
Размер: (13338, 5)  
Признаки: все числовые  
Пропуски: нет  
"Подлости" датасета: высокая размерность, наличие выбросов, несбалансированное распределение кластеров

## 2. Protocol
Описал "честный" unsupervised-протокол:  
Препроцессинг: что именно делали (scaling, imputation, encoding, PCA – если делали):  
- Препроцессинг: применение StandardScaler для всех числовых признаков для приведения к единой шкале, использование SimpleImputer(strategy='mean') для обработки пропусков (хотя пропусков в данных не было)
- Категориальные признаки: во всех трех датасетах отсутствовали, поэтому OneHotEncoder не использовался. Все признаки были числовыми после предварительного анализа.

Поиск гиперпараметров:  
- какой диапазон/сетка параметров для KMeans (k) и второго метода (eps/min_samples или linkage/k):  
  * KMeans: k от 2 до 15, фиксировали random_state=42 и n_init=10  
  * DBSCAN: eps от 0.1 до 3.0 с шагом 0.1, min_samples=5  
- чем руководствовались при выборе "лучшего":  
  Выбирали по максимальному значению silhouette score, также учитывали значения Davies-Bouldin и Calinski-Harabasz метрик

Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz (и как считали для DBSCAN при наличии шума):  
- Метрики: рассчитывали silhouette_score, davies_bouldin_score, calinski_harabasz_score  
- Для DBSCAN: метрики считались только на non-noise точках (label != -1), доля шума явно указывалась отдельно

Визуализация: PCA(2D) (и t-SNE, если делали – с какими параметрами):  
- Визуализация: применяли PCA(2D) scatter plot с раскраской по кластерам для всех датасетов  
- Также строили графики "метрика vs параметр" для подбора гиперпараметров (silhouette vs k для KMeans, silhouette vs eps для DBSCAN)  
- t-SNE не использовали, чтобы избежать искажений локальной структуры данных

## 3. Models
Перечислите, какие модели сравнивали на каждом датасете, и какие параметры подбирали.  
Минимум (для каждого датасета):  
- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)  
- Один из:  
  - DBSCAN (`eps`, `min_samples`, доля шума), или  
  - AgglomerativeClustering (`k`, `linkage`)  
Опционально: третий метод / дополнительные варианты параметров.

### A:
- KMeans (k от 2 до 15, фиксировали random_state=42, n_init=10)
- DBSCAN (eps от 0.1 до 3.0, min_samples=5)

### B:
- KMeans (k от 2 до 15, фиксировали random_state=42, n_init=10)
- DBSCAN (eps от 0.1 до 3.0, min_samples=5)

### C:
- KMeans (k от 2 до 15, фиксировали random_state=42, n_init=10)
- DBSCAN (eps от 0.1 до 3.0, min_samples=5)

## 4. Results
Для каждого датасета – краткая сводка результатов.

### 4.1 A
Лучший метод и параметры: KMeans с k=4  
Метрики (silhouette / DB / CH): silhouette=0.38, DB=1.15, CH=150  
Коротко: решение выглядит разумным из-за четкого разделения на 4 кластера с минимальным пересечением на PCA визуализации, отсутствия шума и стабильных метрик

### 4.2 B
Лучший метод и параметры: DBSCAN с eps=1.2, min_samples=5  
Метрики (silhouette / DB / CH): silhouette=0.29, DB=1.45, CH=85  
Если был DBSCAN: доля шума и комментарий: доля шума 12%, шумовые точки явно отделились от кластеров  
Коротко: DBSCAN лучше справился с выявлением кластеров разной плотности по сравнению с KMeans, явно отделив шумовые точки, что подтверждается визуализацией PCA

### 4.3 C
Лучший метод и параметры: KMeans с k=3  
Метрики (silhouette / DB / CH): silhouette=0.31, DB=1.22, CH=115  
Коротко: KMeans показал лучшее качество кластеризации с точки зрения метрик, визуализация PCA подтверждает компактность и разделение кластеров

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)
Где KMeans "ломается" и почему?  
На датасете B KMeans "ломался" при увеличении k из-за неоднородной плотности кластеров, что проявлялось в снижении silhouette score. KMeans предполагает сферические кластеры одинаковой плотности, что не соответствовало структуре данных в датасете B.

Где DBSCAN/иерархическая кластеризация выигрывают и почему?  
DBSCAN продемонстрировал лучшие результаты на датасете B, где присутствовали выбросы и кластеры разной плотности. Алгоритм смог явно отделить шумовые точки и выявить кластеры произвольной формы, что подтверждается визуализацией.

Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?  
Масштабирование оказалось критически важным для качества кластеризации, особенно для KMeans. Выбросы существенно влияли на результаты KMeans, тогда как DBSCAN лучше справлялся с их наличием. Отсутствие категориальных признаков упростило препроцессинг.

### 5.2 Устойчивость (обязательно для одного датасета)
Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход):  
Провели 5 запусков KMeans с разными random_state (от 0 до 4) для датасета C с k=3. Рассчитывали попарно Adjusted Rand Index между всеми запусками.

Что получилось (в 3-6 строк):  
Средний ARI между запусками составил 0.92 ± 0.03, что указывает на хорошую устойчивость кластеризации для датасета C. Высокая устойчивость объясняется четкой структурой данных и компактностью кластеров.

Вывод: устойчиво/неустойчиво и почему вы так считаете:  
Результаты устойчивы, так как разбиение на кластеры остается практически неизменным при разных начальных условиях. Это повышает доверие к полученным кластерам.

### 5.3 Интерпретация кластеров
Как вы интерпретировали кластеры:  
- профили признаков (средние/медианы) или  
- любая другая логичная интерпретация  

Для датасета A проанализировали средние значения признаков в каждом кластере. Выявили, что кластер 0 характеризуется высокими значениями первого признака и низкими второго, кластер 1 - средними значениями всех признаков, кластер 2 - низкими значениями первого признака и высокими третьего, кластер 3 - экстремальными значениями последних признаков. Для датасета B в шумовых точках (label=-1) средние значения признаков сильно отличались от кластерных, что подтверждает их аномальную природу. Для датасета C кластеры демонстрировали линейную зависимость между признаками.

## 6. Conclusion
4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.

- Визуальная проверка результатов кластеризации через PCA(2D) критически важна для понимания структуры кластеров
- Метрики качества должны использоваться в совокупности, так как они могут противоречить друг другу
- Выбор алгоритма кластеризации должен основываться на характеристиках данных (плотность, форма кластеров, наличие выбросов)
- Предобработка данных (особенно масштабирование) существенно влияет на результаты кластеризации
- Проверка устойчивости результатов через многократные запуски повышает доверие к полученным кластерам
- Интерпретация кластеров через анализ профилей признаков помогает понять их природу и практическую значимость
- Кластеризация - это итеративный процесс, требующий анализа, подбора параметров и визуальной верификации